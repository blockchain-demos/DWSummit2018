{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote_ED_Processor\n",
    "\n",
    "- 1.  Start a remote Spark Driver - running in YARN. This will run a long running Kafka Producer/Consumer.\n",
    "- 2.  Load Web3 and the Smart Contract ABI for the Etherdelta Smart Contract\n",
    "- 3.  Consume all kafka messages from [**Remote_Eth_Producer**](./Remote_Eth_Producer.ipynb)\n",
    "- 4.  Detects Volume Manipulation occuring, and produce to a new Kafka \"SelfPump\" topic\n",
    "    - Applies the ContractABI to messages consumed, to apply the proper Schema for that Ethereum Event log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.0 Load sparkmagic \n",
    "https://github.com/jupyter-incubator/sparkmagic\n",
    "\n",
    "Sparkmagic is a set of tools for interactively working with remote Spark clusters through Livy, a Spark REST server.\n",
    "\n",
    "Any cells ran with `%%spark` will execute against a remote spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create a remote livy session\n",
    "\n",
    "Define spark configuration to use for this session.\n",
    "\n",
    "- We can leverage a **python virtual environment** in our remote Spark Session:\n",
    "  - `gethdemo.tar.gz` contains a conda virtual environment created from `./py_kafka_reqs.txt`\n",
    "  - `gethdemo.tar.gz` is available on `hdfs://user/noobie/`\n",
    "\n",
    "- Since kafka does not fully support [Delegation Tokens](https://cwiki.apache.org/confluence/display/KAFKA/KIP-48+Delegation+token+support+for+Kafka#KIP-48DelegationtokensupportforKafka-APIsandrequest/responseclasses), we can also pass in a keytab through `--files`, if connecting to a kerberized Kafka Broker.\n",
    "\n",
    "- Livy sessions can take up to 60 seconds to start. Be patient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark config \n",
    "{\n",
    "  \"name\":\"remoteEDProcessor\",\n",
    "  \"driverMemory\":\"2G\",\n",
    "  \"numExecutors\":1,\n",
    "  \"proxyUser\":\"noobie\",\n",
    "  \"archives\": [\"hdfs:///user/noobie/gethdemo.tar.gz\"],\n",
    "  \"files\": [\"hdfs:///user/noobie/etherdelta_abi.json\",\n",
    "           \"/user/noobie/noobie.keytab\"],\n",
    "  \"queue\": \"streaming\",\n",
    "  \"conf\": {\"spark.yarn.appMasterEnv.PYSPARK_PYTHON\":\"gethdemo.tar.gz/demo/bin/python3.5\",\n",
    "          \"spark.jars.packages\":\"org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>291</td><td>application_1527994885375_0069</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hdp-3.demo.url:8088/proxy/application_1527994885375_0069/\">Link</a></td><td><a target=\"_blank\" href=\"http://hdp-5.demo.url:8042/node/containerlogs/container_e56_1527994885375_0069_01_000001/noobie\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%spark add -s edprocessor -l python -u http://hdp-3.demo.url:8999 --auth Kerberos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Obtain a keberos ticket for connecting to Kafka\n",
    "keytab was added to Yarn distributed cache via the `--files` option in the spark config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import subprocess\n",
    "kinit = '/usr/bin/kinit'\n",
    "kinit_args = [kinit, '-kt', \"noobie.keytab\" , \"noobie\"]\n",
    "subprocess.check_output(kinit_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.0 Connect to Ethereum using Web3 from within the spark session\n",
    "\n",
    "Web3 is a python library for interacting with Ethereum http://web3py.readthedocs.io/en/stable/. \n",
    "Its API is derived from the [Web3.js](https://github.com/ethereum/wiki/wiki/JavaScript-API) Javascript API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest block: 5767704"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "from web3 import Web3, HTTPProvider, IPCProvider\n",
    "\n",
    "gethRPCUrl='http://10.132.86.5:8545'\n",
    "web3 = Web3(HTTPProvider(gethRPCUrl))\n",
    "\n",
    "# Retrieve the last block number available from geth RPC\n",
    "currentblock = web3.eth.getBlock('latest').number\n",
    "print(\"Latest block: \" + str(currentblock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define a HexJsonEncoder to cleanse Web3 response\n",
    "\n",
    "Web3 returns an AttributeDict containing `HexBytes`, which is not recognized by Json or Kafka. \n",
    "https://github.com/ethereum/web3.py/issues/782\n",
    "\n",
    "See cls in https://docs.python.org/2/library/json.html#basic-usage\n",
    "\n",
    "```\n",
    "usage: \n",
    "  blockjson = json.dumps(somePydDict, cls=HexJsonEncoder)    \n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "from hexbytes import HexBytes\n",
    "import json\n",
    "class HexJsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, HexBytes):\n",
    "            return obj.hex()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Known Hashes For Ethedelta's Contract\n",
    "\n",
    "- **TOPIC IDs** - Methods within a Smart Contract have a **unique** [TOPIC](http://solidity.readthedocs.io/en/develop/contracts.html?highlight=topic#events) Id\n",
    "\n",
    "- **Contract Address** - The smart contract address we are looking at, in this case EtherDelta https://etherscan.io/address/0x8d12a197cb00d4747a1fe03395095ce2a5cc6819#code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "ETHERDELTA_CONTRACT_ADDR = '0x8d12A197cB00D4747a1fe03395095ce2A5CC6819'\n",
    "\n",
    "ETHERDELTA_TRADE_METHOD_TOPICID='0x6effdda786735d5033bfad5f53e5131abcced9e52be6c507b62d639685fbed6d'\n",
    "ETHERDELTA_CANCEL_METHOD_TOPICID='0x1e0b760c386003e9cb9bcf4fcf3997886042859d9b6ed6320e804597fcdb28b0'\n",
    "ETHERDELTA_DEPOSIT_METHOD_TOPICID='0xdcbc1c05240f31ff3ad067ef1ee35ce4997762752e3a095284754544f4c709d7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load the ED Contract ABI \n",
    "\n",
    "When a solidity contract is deployed to the Ethereum Blockchain, there is a corresponding [\"Contract ABI\"](https://web3js.readthedocs.io/en/1.0/web3-eth-abi.html#web3-eth-abi) created, which can be used to extract the schema and data for the [output of Events](https://web3js.readthedocs.io/en/1.0/web3-eth-contract.html#contract-events) being invoked from a smart contract. \n",
    "\n",
    "- `hdfs:///user/noobie/etherdelta_abi.json` was retrieved from [etherscan](https://api.etherscan.io/api?module=contract&action=getabi&address=0x8d12a197cb00d4747a1fe03395095ce2a5cc6819)\n",
    "\n",
    "[Example Parsing of 1 transaction for reference](./Images/process_eth_logs_with_abi.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "with open('etherdelta_abi.json') as f:\n",
    "    ETHERDELTA_CONTRACT_ABI = json.load(f)\n",
    "# Create a local instance of the smart contract\n",
    "ED_CONTRACT_OBJ = web3.eth.contract(address=ETHERDELTA_CONTRACT_ADDR, \n",
    "                                    abi=ETHERDELTA_CONTRACT_ABI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.0 Create a consumer for eth_eventlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "consumer = KafkaConsumer(bootstrap_servers=['hdp-3.demo.url:6667',\n",
    "                                           'hdp-5.demo.url:6667',\n",
    "                                           'hdp-6.demo.url:6667'],\n",
    "                         security_protocol=\"SASL_PLAINTEXT\",\n",
    "                         sasl_mechanism=\"GSSAPI\",\n",
    "                         auto_offset_reset='earliest',\n",
    "                         client_id='edprocessor',\n",
    "                         request_timeout_ms=501,\n",
    "                         consumer_timeout_ms=500,\n",
    "                         max_poll_interval_ms=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sample Data Consumed:\n",
    "```\n",
    "{'address': '0x8d12A197cB00D4747a1fe03395095ce2A5CC6819',\n",
    " 'blockHash': '0x8c11efca021f3260fab2f4736718d94acb6530a567d5462e57c484ff2e04aa3d',\n",
    " 'blockNumber': 5682604,\n",
    " 'data': '0x..',\n",
    " 'logIndex': 1,\n",
    " 'topics': ['0x6effdda786735d5033bfad5f53e5131abcced9e52be6c507b62d639685fbed6d'],\n",
    " 'transactionHash': '0x..',\n",
    " 'transactionIndex': 4,\n",
    " 'transactionLogIndex': '0x0',\n",
    " 'type': 'mined'},\n",
    " ```\n",
    " \n",
    " \n",
    "When we subscribe to this topic, we'll need to filter for all transactions being executed from:\n",
    "\n",
    "```\n",
    "'address' : ETHERDELTA_CONTRACT_ADDR\n",
    "'topics' : ETHERDELTA_TRADE_METHOD_TOPICID\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.0 Define the producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "producer = KafkaProducer(bootstrap_servers=['hdp-4.demo.url:6667',\n",
    "                                            'hdp-5.demo.url:6667',\n",
    "                                            'hdp-6.demo.url:6667'],\n",
    "                        security_protocol=\"SASL_PLAINTEXT\",\n",
    "                        sasl_mechanism=\"GSSAPI\",\n",
    "                        value_serializer=lambda m: json.dumps(m, cls=HexJsonEncoder).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Run the full consumer/producer to process ED Trades\n",
    "Run the consumer for a given period of time\n",
    "\n",
    "This will:\n",
    " \n",
    "- Consume: `EVENT_TOPIC_TO_CONSUME`\n",
    "- Filter For trades occuring on the ED Contract: \n",
    "    ```\n",
    "    'address' : ETHERDELTA_CONTRACT_ADDR\n",
    "    'topics'  : ETHERDELTA_TRADE_METHOD_TOPICID\n",
    "    ```\n",
    "- Parse out trades who have the same `buyer` and `seller`\n",
    "- Produce all \"Self Pump\" trades to a new topic: `SELF_PUMP_TOPIC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosuming from:eth_eventlogs_sat\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d7b0b70>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d77f4e0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d77f908>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f390>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f198>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f828>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f2b0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f320>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70f668>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d6fd6d8>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70f710>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d6fd5f8>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d754358>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70ff98>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70f278>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d7545c0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d754208>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d754cc0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73fb38>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73fe10>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d754cc0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70f438>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d754d30>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d6fdef0>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d70fa90>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73fb00>\n",
      "Found a Market Pumper Executing his own order!\n",
      "<kafka.producer.future.FutureRecordMetadata object at 0x7fac2d73f0f0>\n",
      "Unexpected error: <class 'TypeError'>"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import sys, time\n",
    "\n",
    "CONSUMER_RUN_SEC = 10\n",
    "\n",
    "# Topic To Consume\n",
    "EVENT_TOPIC_TO_CONSUME=\"eth_eventlogs_sat\"\n",
    "consumer.subscribe([EVENT_TOPIC_TO_CONSUME])\n",
    "print(\"Cosuming from:\" + EVENT_TOPIC_TO_CONSUME)\n",
    "\n",
    "# Topic To Produce Market Manipulation trades to\n",
    "SELF_PUMP_TOPIC=\"selfpump_trades_sat\"\n",
    "\n",
    "try:\n",
    "    global CONSUMER_RUN_SEC\n",
    "    CONSUMER_START=0\n",
    "    \n",
    "    while CONSUMER_START < CONSUMER_RUN_SEC:\n",
    "        for message in consumer:\n",
    "\n",
    "            consumermsg = json.loads(json.loads(message.value.decode('utf-8')))\n",
    "            # Filter For ED Smart Contract\n",
    "            if consumermsg['address'] == ETHERDELTA_CONTRACT_ADDR:\n",
    "\n",
    "                # Filter for ED TRADE METHOD\n",
    "                if consumermsg['topics'][0] == ETHERDELTA_TRADE_METHOD_TOPICID: \n",
    "\n",
    "                    # Query Web3 for the TransactionReceipt which includes full log hexdata\n",
    "                    tx_receipt = web3.eth.getTransactionReceipt(consumermsg['transactionHash'])\n",
    "                    try:\n",
    "                        # Use the ED_CONTRACT_OBJ ABI To process the tx_receipt for the \"Trade()\" method\n",
    "                        # Which returns the data with proper column headers\n",
    "                        ed_etl_trade = dict(ED_CONTRACT_OBJ.events.Trade().processReceipt(tx_receipt)[0])\n",
    "                    except:\n",
    "                        print(\"Error:\", sys.exc_info()[0])\n",
    "                        break\n",
    "                        \n",
    "                    # Skip Invalid transactions - Those posted to blockchain which do not include logs    \n",
    "                    if ed_etl_trade is not None:\n",
    "                        # ['args'] is Returned as AttributeDict -- Flatten by calling dict()\n",
    "                        ed_etl_trade['args'] =dict(ed_etl_trade['args']) \n",
    "\n",
    "                    # Check for Buyer == Seller\n",
    "                        if ed_etl_trade['args']['get'] == ed_etl_trade['args']['give']:\n",
    "                    # PRODUCE to SELF_PUMP_TOPIC\n",
    "                            print(\"Found a Market Pumper Executing his own order!\")\n",
    "                            producer.send(SELF_PUMP_TOPIC, ed_etl_trade)                          \n",
    "                        \n",
    "        CONSUMER_START=CONSUMER_START+1\n",
    "        time.sleep(1)\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
